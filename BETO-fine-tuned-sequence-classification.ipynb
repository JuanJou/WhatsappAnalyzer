{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afbdcfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PyTorch\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import torch\n",
    "\n",
    "#transformer\n",
    "from transformers import BertForMaskedLM, DistilBertTokenizer, DistilBertModel, BertTokenizer, BertForSequenceClassification\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "\n",
    "#dataset\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# # Setting up the device for GPU usage\n",
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "\n",
    "#utils\n",
    "from sklearn import metrics\n",
    "from tqdm.notebook import tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c0de5e",
   "metadata": {},
   "source": [
    "## Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5edbae2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_label = {\n",
    "    0: \"Juan Jouglard\",\n",
    "    1: \"Mopi\",\n",
    "    2: \"Juan Dimatz\",\n",
    "    3: \"Agus Streiten\",\n",
    "    4: \"Agus Superi\",\n",
    "    5: \"Mati Gonzalez\",\n",
    "    6: \"Bian Artola\",\n",
    "    7: \"German Gomez\",\n",
    "    8: \"Juan Olmedo\",\n",
    "    9: \"Mati Garcia\",\n",
    "    10: \"Igna Suburu\",\n",
    "    11: \"Tomi Felder\",\n",
    "    12: \"Masa\",\n",
    "}\n",
    "\n",
    "label_to_id = {\n",
    "    \"Juan Jouglard\": 0,\n",
    "    \"Mopi\": 1,\n",
    "    \"Juan Dimatz\": 2,\n",
    "    \"Agus Streiten\": 3,\n",
    "    \"Agus Superi\": 4,\n",
    "    \"Mati Gonzalez\": 5,\n",
    "    \"Bian Artola\": 6,\n",
    "    \"German Gomez\": 7,\n",
    "    \"Juan Olmedo\": 8,\n",
    "    \"Mati Garcia\": 9,\n",
    "    \"Igna Suburu\": 10,\n",
    "    \"Tomi Felder\": 11,\n",
    "    \"Masa\": 12,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2382a9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_one_hot_encoding(label):\n",
    "    one_hot = np.zeros(13, dtype=int)\n",
    "    if label in label_to_id.keys():\n",
    "        one_hot[label_to_id[label]] = 1\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2280a202",
   "metadata": {},
   "outputs": [],
   "source": [
    "#alloy_ds = load_dataset(\"csv\", data_files={\"train\": \"../wp/train_alloy_ds.csv\", \"test\": \"../wp/test_alloy_ds.csv\"})\n",
    "alloy_ds = pd.read_csv(\"../wp/alloy_dataset\")\n",
    "alloy_ds[\"label\"] = alloy_ds[\"label\"].map(transform_to_one_hot_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7765226d",
   "metadata": {},
   "outputs": [],
   "source": [
    "alloy_ds = alloy_ds.tail(1000) #Keep only first 100 rows for educational purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c413ef1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69470</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]</td>\n",
       "      <td>ahora sí voy a ir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69471</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]</td>\n",
       "      <td>para joderte a vos nomás</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69472</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>sos puro humo bro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69473</th>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>hagan esa tierlist asi nos cagamos bien a piñas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69474</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "      <td>el problema es que me gusta todo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70465</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]</td>\n",
       "      <td>por obvios motivos todavía no estoy en condici...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70466</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]</td>\n",
       "      <td>yo tengo oficina por ahora</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70467</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "      <td>me gusta ña idea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70468</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "      <td>pero no tengo note del laburo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70469</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "      <td>meconplica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         label  \\\n",
       "69470  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]   \n",
       "69471  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]   \n",
       "69472  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]   \n",
       "69473  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "69474  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]   \n",
       "...                                        ...   \n",
       "70465  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]   \n",
       "70466  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]   \n",
       "70467  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]   \n",
       "70468  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]   \n",
       "70469  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]   \n",
       "\n",
       "                                                    text  \n",
       "69470                                  ahora sí voy a ir  \n",
       "69471                           para joderte a vos nomás  \n",
       "69472                                  sos puro humo bro  \n",
       "69473    hagan esa tierlist asi nos cagamos bien a piñas  \n",
       "69474                   el problema es que me gusta todo  \n",
       "...                                                  ...  \n",
       "70465  por obvios motivos todavía no estoy en condici...  \n",
       "70466                         yo tengo oficina por ahora  \n",
       "70467                                   me gusta ña idea  \n",
       "70468                      pero no tengo note del laburo  \n",
       "70469                                         meconplica  \n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alloy_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa396f6",
   "metadata": {},
   "source": [
    "## Load model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "619947e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at pytorch/ were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# create the tokenizer and the model\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"pytorch/\", do_lower_case=False, num_labels=13)\n",
    "#tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "base_model = BertForSequenceClassification.from_pretrained(\"pytorch/\")\n",
    "#base_model = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "e = base_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8700d4",
   "metadata": {},
   "source": [
    "### Custom parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16a61082",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 200\n",
    "TRAIN_BATCH_SIZE = 8\n",
    "VALID_BATCH_SIZE = 4\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 1e-05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13977043",
   "metadata": {},
   "source": [
    "## Tokenize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1aedbd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_message(text):\n",
    "        t = tokenizer(text, padding=\"max_length\",add_special_tokens=True, truncation=True, max_length=MAX_LEN, return_token_type_ids=True)\n",
    "        return t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a222670f",
   "metadata": {},
   "source": [
    "## Custom Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65f73c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WhatsappDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.text = dataframe.text\n",
    "        self.targets = self.data.label\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "    \n",
    "    def tokenize_message(self, text):\n",
    "        t = self.tokenizer(text,\n",
    "                           padding=\"max_length\",\n",
    "                           add_special_tokens=True,\n",
    "                           truncation=True,\n",
    "                           max_length=MAX_LEN,\n",
    "                           return_token_type_ids=True)\n",
    "        return t\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.text[index])\n",
    "        text = \" \".join(text.split())\n",
    "\n",
    "        inputs = self.tokenize_message(\n",
    "            text\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b74aed",
   "metadata": {},
   "source": [
    "### Create proper datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d804f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL Dataset: (1000, 2)\n",
      "TRAIN Dataset: (800, 2)\n",
      "TEST Dataset: (200, 2)\n"
     ]
    }
   ],
   "source": [
    "# Creating the dataset and dataloader for the neural network\n",
    "\n",
    "train_size = 0.8\n",
    "train_dataset=alloy_ds.sample(frac=train_size,random_state=200)\n",
    "test_dataset=alloy_ds.drop(train_dataset.index).reset_index(drop=True)\n",
    "train_dataset = train_dataset.reset_index(drop=True)\n",
    "\n",
    "\n",
    "print(\"FULL Dataset: {}\".format(alloy_ds.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
    "\n",
    "training_set = WhatsappDataset(train_dataset, tokenizer, MAX_LEN)\n",
    "testing_set = WhatsappDataset(test_dataset, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693b51af",
   "metadata": {},
   "source": [
    "### Create dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff059575",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "testing_loader = DataLoader(testing_set, **test_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9cc8a2",
   "metadata": {},
   "source": [
    "### Create custom model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89ac8426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WhatsappPredictor(\n",
       "  (l1): BertForMaskedLM(\n",
       "    (bert): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(31002, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (token_type_embeddings): Embedding(2, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (4): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (5): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (6): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (7): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (8): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (9): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (10): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (11): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (cls): BertOnlyMLMHead(\n",
       "      (predictions): BertLMPredictionHead(\n",
       "        (transform): BertPredictionHeadTransform(\n",
       "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (decoder): Linear(in_features=768, out_features=31002, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (l2): Dropout(p=0.3, inplace=False)\n",
       "  (l3): Linear(in_features=31002, out_features=13, bias=True)\n",
       "  (l4): Softmax(dim=0)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class WhatsappPredictor(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(WhatsappPredictor, self).__init__()\n",
    "        self.l1 = base_model\n",
    "        self.l2 = torch.nn.Dropout(0.3)\n",
    "        self.l3 = torch.nn.Linear(31002, 13)\n",
    "        self.l4 = torch.nn.Softmax(dim=0)\n",
    "    \n",
    "    def forward(self, ids, mask, token_type_ids):\n",
    "        output_1, = self.l1(\n",
    "            ids,\n",
    "            attention_mask = mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            return_dict=False)\n",
    "        index = torch.tensor([0]).to(device)\n",
    "        pool_output = torch.index_select(output_1, 1, index).squeeze() #Keeps only the output for the first character in each sentence\n",
    "        drop_out = self.l2(pool_output)\n",
    "        #print(\"Output 1\", pool_output.shape) # tensor[batch_size][max_length][vocab_size] 4x200x31000\n",
    "        linear_output = self.l3(drop_out)\n",
    "        probability = self.l4(linear_output)\n",
    "        #output = self.l3(output_2)\n",
    "        return probability\n",
    "\n",
    "model = WhatsappPredictor()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250c4779",
   "metadata": {},
   "source": [
    "### Loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d19d664c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(outputs, targets):\n",
    "    label = targets.argmax(1)\n",
    "    return torch.nn.CrossEntropyLoss()(outputs, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afa1a28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cbfc21",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "514189e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    for _,data in enumerate(tqdm_notebook(training_loader), 0):\n",
    "        ids = data['ids'].to(device, dtype = torch.long)\n",
    "        mask = data['mask'].to(device, dtype = torch.long)\n",
    "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "        targets = data['targets'].to(device, dtype = torch.float)\n",
    "        \n",
    "        outputs = model(ids, mask, token_type_ids)\n",
    "        #print(f\"Model output: {outputs.shape}\")\n",
    "        \n",
    "        #print(f\"Model output: {outputs[0]}\")\n",
    "        #print(f\"Actual target: {targets[0]}\")\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch: {epoch}, Loss:  {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2712c357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce76c3e00a1f4eaeaf3c3ac8c3a6686f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss:  2.611661195755005\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abdf648e1d5b44608edca02b727f15a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss:  2.6951305866241455\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a6d5e8f3a094e3e92a2eec10698fc85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Loss:  2.5038177967071533\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dae3c4fbd7341dabe5311a1504e36f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Loss:  2.206146001815796\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6240de42bcda4eb985fa3f9c09ab1d50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Loss:  2.2506237030029297\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f754c0e2b58147f2a5d15967bc23b224",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Loss:  2.4155356884002686\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4857081631f4263a9ee13c87485c83f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Loss:  2.3714358806610107\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0c3a746575b40ef9b1f26c8e8d6d108",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Loss:  2.1632080078125\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34a9134adb104976ac691de0ff1a3482",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Loss:  2.200254440307617\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76c7a9b624724d2199f5e1c08843c7c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Loss:  2.1568808555603027\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c37489",
   "metadata": {},
   "source": [
    "## Validating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29933202",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(epoch):\n",
    "    model.eval()\n",
    "    fin_targets=[]\n",
    "    fin_outputs=[]\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(tqdm_notebook(testing_loader), 0):\n",
    "            ids = data['ids'].to(device, dtype = torch.long)\n",
    "            mask = data['mask'].to(device, dtype = torch.long)\n",
    "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "            targets = data['targets'].to(device, dtype = torch.float)\n",
    "            outputs = model(ids, mask, token_type_ids)\n",
    "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
    "            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
    "    return fin_outputs, fin_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f98ad042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac6ca770a31f49aaadab7861f86340c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score = 0.0\n",
      "F1 Score (Micro) = 0.1402002861230329\n",
      "F1 Score (Macro) = 0.13407803658367115\n"
     ]
    }
   ],
   "source": [
    "outputs, targets = validation(1)\n",
    "outputs = np.array(outputs) >= 0.5\n",
    "accuracy = metrics.accuracy_score(targets, outputs)\n",
    "f1_score_micro = metrics.f1_score(targets, outputs, average='micro')\n",
    "f1_score_macro = metrics.f1_score(targets, outputs, average='macro')\n",
    "print(f\"Accuracy Score = {accuracy}\")\n",
    "print(f\"F1 Score (Micro) = {f1_score_micro}\")\n",
    "print(f\"F1 Score (Macro) = {f1_score_macro}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "61c60824",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "    tokens = tokenize_message(text)\n",
    "    input_ids = torch.tensor([tokens[\"input_ids\"]], dtype=torch.long).to(device, dtype = torch.long)\n",
    "    attention_mask = torch.tensor([tokens[\"attention_mask\"]], dtype=torch.long).to(device, dtype = torch.long)\n",
    "    token_type_ids = torch.tensor([tokens[\"token_type_ids\"]], dtype=torch.long).to(device, dtype = torch.long)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        ids = input_ids.to(device, dtype = torch.long)\n",
    "        mask = attention_mask.to(device, dtype = torch.long)\n",
    "        token_type_ids = token_type_ids.to(device, dtype = torch.long)\n",
    "        outputs = model(ids, mask, token_type_ids)\n",
    "  \n",
    "    return id_to_label[outputs.argmax().item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f9f1805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Juan Dimatz'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"se recontra pico\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
